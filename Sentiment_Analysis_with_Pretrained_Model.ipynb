{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-addons in /opt/conda/lib/python3.8/site-packages (0.13.0)\n",
      "Requirement already satisfied: typeguard>=2.7 in /opt/conda/lib/python3.8/site-packages (from tensorflow-addons) (2.12.1)\n",
      "Requirement already satisfied: tensorflow-text in /opt/conda/lib/python3.8/site-packages (2.5.0)\n",
      "Requirement already satisfied: tensorflow-hub>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow-text) (0.12.0)\n",
      "Requirement already satisfied: tensorflow<2.6,>=2.5.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow-text) (2.5.1)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow-hub>=0.8.0->tensorflow-text) (1.19.5)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow-hub>=0.8.0->tensorflow-text) (3.17.3)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text) (1.1.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text) (3.1.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /opt/conda/lib/python3.8/site-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text) (3.3.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /opt/conda/lib/python3.8/site-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text) (1.1.2)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text) (1.12)\n",
      "Requirement already satisfied: wheel~=0.35 in /opt/conda/lib/python3.8/site-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text) (0.35.1)\n",
      "Requirement already satisfied: absl-py~=0.10 in /opt/conda/lib/python3.8/site-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text) (0.10.0)\n",
      "Requirement already satisfied: tensorboard~=2.5 in /opt/conda/lib/python3.8/site-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text) (2.6.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /opt/conda/lib/python3.8/site-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text) (1.6.3)\n",
      "Requirement already satisfied: grpcio~=1.34.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text) (1.34.1)\n",
      "Requirement already satisfied: keras-nightly~=2.5.0.dev in /opt/conda/lib/python3.8/site-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text) (2.5.0.dev2021032900)\n",
      "Requirement already satisfied: six~=1.15.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text) (1.15.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text) (2.5.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /opt/conda/lib/python3.8/site-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text) (1.12.1)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /opt/conda/lib/python3.8/site-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text) (3.7.4.2)\n",
      "Requirement already satisfied: gast==0.4.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text) (0.4.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (0.6.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (2.24.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (1.34.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (3.2.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (49.6.0.post20200814)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (1.7.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (0.4.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (1.25.10)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /opt/conda/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (4.6)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (4.1.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (3.0.1)\n"
     ]
    }
   ],
   "source": [
    "#install addons for \n",
    "!pip install tensorflow-addons\n",
    "!pip install transformers[tf-cpu]\n",
    "\n",
    "from transformers import BertTokenizer, TFBertModel \n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Embedding, Dense, Input, Dropout, LayerNormalization, GlobalAveragePooling1D, Flatten\n",
    "from tensorflow_addons.layers import MultiHeadAttention\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import csv \n",
    "import os\n",
    "import shutil\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the data from Kaggle https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews/tasks?taskId=588 \n",
    "# Load the 1mdb datasets from Kaggle\n",
    "kaggle_imdb_file = 'datasets/IMDB_Dataset.csv' \n",
    "data_x = []\n",
    "data_y = []\n",
    "with open(kaggle_imdb_file, 'r') as csvfile: \n",
    "  filereader = csv.reader(csvfile, delimiter=',', dialect='excel')\n",
    "  next(filereader)\n",
    "  for row in filereader:\n",
    "    data_x.append(row[0]) \n",
    "    label = 1 if row[1] == 'positive' else 0 \n",
    "    data_y.append(label)\n",
    "# Prepare the data into trainable format\n",
    "data_x = np.array(data_x)\n",
    "data_y = np.array(data_y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_x, data_y, test_size=0.2, random_state=29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers[tf-cpu]\n",
      "  Downloading transformers-4.9.2-py3-none-any.whl (2.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.6 MB 4.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2021.8.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (738 kB)\n",
      "\u001b[K     |████████████████████████████████| 738 kB 13.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sacremoses\n",
      "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
      "\u001b[K     |████████████████████████████████| 895 kB 10.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers[tf-cpu]) (5.3.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers[tf-cpu]) (4.48.2)\n",
      "Collecting huggingface-hub==0.0.12\n",
      "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers[tf-cpu]) (1.19.5)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from transformers[tf-cpu]) (20.4)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 30.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers[tf-cpu]) (2.24.0)\n",
      "Collecting onnxconverter-common; extra == \"tf-cpu\"\n",
      "  Downloading onnxconverter_common-1.8.1-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 9.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting keras2onnx; extra == \"tf-cpu\"\n",
      "  Downloading keras2onnx-1.7.0-py3-none-any.whl (96 kB)\n",
      "\u001b[K     |████████████████████████████████| 96 kB 7.7 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-cpu>=2.3; extra == \"tf-cpu\"\n",
      "  Downloading tensorflow_cpu-2.6.0-cp38-cp38-manylinux2010_x86_64.whl (172.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 172.4 MB 66 kB/s s eta 0:00:01    |███████████████▍                | 83.1 MB 39.6 MB/s eta 0:00:03\n",
      "\u001b[?25hRequirement already satisfied: joblib in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers[tf-cpu]) (0.16.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers[tf-cpu]) (7.1.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers[tf-cpu]) (1.15.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from huggingface-hub==0.0.12->transformers[tf-cpu]) (3.7.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->transformers[tf-cpu]) (2.4.7)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests->transformers[tf-cpu]) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers[tf-cpu]) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers[tf-cpu]) (1.25.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers[tf-cpu]) (2020.6.20)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.8/site-packages (from onnxconverter-common; extra == \"tf-cpu\"->transformers[tf-cpu]) (3.17.3)\n",
      "Collecting onnx\n",
      "  Downloading onnx-1.10.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (12.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.3 MB 15.3 MB/s eta 0:00:01    |███▊                            | 1.4 MB 15.3 MB/s eta 0:00:01     |██████▌                         | 2.5 MB 15.3 MB/s eta 0:00:01     |██████████████                  | 5.3 MB 15.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting fire\n",
      "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
      "\u001b[K     |████████████████████████████████| 87 kB 9.9 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: keras-preprocessing~=1.1.2 in /opt/conda/lib/python3.8/site-packages (from tensorflow-cpu>=2.3; extra == \"tf-cpu\"->transformers[tf-cpu]) (1.1.2)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow-cpu>=2.3; extra == \"tf-cpu\"->transformers[tf-cpu]) (1.1.0)\n",
      "Collecting clang~=5.0\n",
      "  Downloading clang-5.0.tar.gz (30 kB)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /opt/conda/lib/python3.8/site-packages (from tensorflow-cpu>=2.3; extra == \"tf-cpu\"->transformers[tf-cpu]) (2.6.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in /opt/conda/lib/python3.8/site-packages (from tensorflow-cpu>=2.3; extra == \"tf-cpu\"->transformers[tf-cpu]) (0.10.0)\n",
      "Requirement already satisfied: gast==0.4.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow-cpu>=2.3; extra == \"tf-cpu\"->transformers[tf-cpu]) (0.4.0)\n",
      "Collecting keras~=2.6\n",
      "  Downloading keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 20.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: google-pasta~=0.2 in /opt/conda/lib/python3.8/site-packages (from tensorflow-cpu>=2.3; extra == \"tf-cpu\"->transformers[tf-cpu]) (0.2.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /opt/conda/lib/python3.8/site-packages (from tensorflow-cpu>=2.3; extra == \"tf-cpu\"->transformers[tf-cpu]) (0.35.1)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow-cpu>=2.3; extra == \"tf-cpu\"->transformers[tf-cpu]) (3.1.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /opt/conda/lib/python3.8/site-packages (from tensorflow-cpu>=2.3; extra == \"tf-cpu\"->transformers[tf-cpu]) (1.6.3)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow-cpu>=2.3; extra == \"tf-cpu\"->transformers[tf-cpu]) (3.3.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow-cpu>=2.3; extra == \"tf-cpu\"->transformers[tf-cpu]) (1.12)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /opt/conda/lib/python3.8/site-packages (from tensorflow-cpu>=2.3; extra == \"tf-cpu\"->transformers[tf-cpu]) (1.12.1)\n",
      "Collecting grpcio<2.0,>=1.37.0\n",
      "  Downloading grpcio-1.39.0-cp38-cp38-manylinux2014_x86_64.whl (4.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.3 MB 21.8 MB/s eta 0:00:01     |███████████▉                    | 1.6 MB 21.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-estimator~=2.6\n",
      "  Downloading tensorflow_estimator-2.6.0-py2.py3-none-any.whl (462 kB)\n",
      "\u001b[K     |████████████████████████████████| 462 kB 17.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow-cpu>=2.3; extra == \"tf-cpu\"->transformers[tf-cpu]) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow-cpu>=2.3; extra == \"tf-cpu\"->transformers[tf-cpu]) (1.7.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow-cpu>=2.3; extra == \"tf-cpu\"->transformers[tf-cpu]) (3.2.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow-cpu>=2.3; extra == \"tf-cpu\"->transformers[tf-cpu]) (49.6.0.post20200814)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow-cpu>=2.3; extra == \"tf-cpu\"->transformers[tf-cpu]) (0.4.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow-cpu>=2.3; extra == \"tf-cpu\"->transformers[tf-cpu]) (1.0.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow-cpu>=2.3; extra == \"tf-cpu\"->transformers[tf-cpu]) (1.34.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow-cpu>=2.3; extra == \"tf-cpu\"->transformers[tf-cpu]) (1.3.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow-cpu>=2.3; extra == \"tf-cpu\"->transformers[tf-cpu]) (4.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow-cpu>=2.3; extra == \"tf-cpu\"->transformers[tf-cpu]) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /opt/conda/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow-cpu>=2.3; extra == \"tf-cpu\"->transformers[tf-cpu]) (4.6)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow-cpu>=2.3; extra == \"tf-cpu\"->transformers[tf-cpu]) (3.0.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow-cpu>=2.3; extra == \"tf-cpu\"->transformers[tf-cpu]) (0.4.8)\n",
      "Building wheels for collected packages: fire, clang\n",
      "  Building wheel for fire (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115928 sha256=f1e52b11777b36867b3211db2bc63bb6893ecbd808a2c2258b5cc60c7db4b69c\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/1f/10/06/2a990ee4d73a8479fe2922445e8a876d38cfbfed052284c6a1\n",
      "  Building wheel for clang (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for clang: filename=clang-5.0-py3-none-any.whl size=30705 sha256=fecca56ea5c29e6b15241cfb38b0472fc8c8dbdc9075355ef804069bce8402e2\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/f1/60/77/22b9b5887bd47801796a856f47650d9789c74dc3161a26d608\n",
      "Successfully built fire clang\n",
      "Installing collected packages: filelock, regex, sacremoses, huggingface-hub, tokenizers, onnx, onnxconverter-common, fire, keras2onnx, clang, keras, grpcio, tensorflow-estimator, tensorflow-cpu, transformers\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: Keras 2.4.3\n",
      "    Uninstalling Keras-2.4.3:\n",
      "      Successfully uninstalled Keras-2.4.3\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.34.1\n",
      "    Uninstalling grpcio-1.34.1:\n",
      "      Successfully uninstalled grpcio-1.34.1\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.5.0\n",
      "    Uninstalling tensorflow-estimator-2.5.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.5.0\n",
      "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "tensorflow 2.5.1 requires grpcio~=1.34.0, but you'll have grpcio 1.39.0 which is incompatible.\n",
      "tensorflow 2.5.1 requires tensorflow-estimator<2.6.0,>=2.5.0, but you'll have tensorflow-estimator 2.6.0 which is incompatible.\n",
      "huggingface-hub 0.0.12 requires packaging>=20.9, but you'll have packaging 20.4 which is incompatible.\u001b[0m\n",
      "Successfully installed clang-5.0 filelock-3.0.12 fire-0.4.0 grpcio-1.39.0 huggingface-hub-0.0.12 keras-2.6.0 keras2onnx-1.7.0 onnx-1.10.1 onnxconverter-common-1.8.1 regex-2021.8.3 sacremoses-0.0.45 tensorflow-cpu-2.6.0 tensorflow-estimator-2.6.0 tokenizers-0.10.3 transformers-4.9.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2eb9225fdc24a9581599169e3efbc4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4343dfeef184059ba63e3e3b064ff5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65746e3ac1ac4a9587d6275d8be6946b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81daf7797c2943e09281e094c4f642eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a78eb1f399ce41f69305b50ee1aa2fdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=536063208.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
      "/opt/conda/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2184: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sample 0 to 100 \n",
      "Processing sample 100 to 200 \n",
      "Processing sample 200 to 300 \n",
      "Processing sample 300 to 400 \n",
      "Processing sample 400 to 500 \n",
      "Processing sample 500 to 600 \n",
      "Processing sample 600 to 700 \n",
      "Processing sample 700 to 800 \n",
      "Processing sample 800 to 900 \n",
      "Processing sample 900 to 1000 \n",
      "Processing sample 1000 to 1100 \n",
      "Processing sample 1100 to 1200 \n",
      "Processing sample 1200 to 1300 \n",
      "Processing sample 1300 to 1400 \n",
      "Processing sample 1400 to 1500 \n",
      "Processing sample 1500 to 1600 \n",
      "Processing sample 1600 to 1700 \n",
      "Processing sample 1700 to 1800 \n",
      "Processing sample 1800 to 1900 \n",
      "Processing sample 1900 to 2000 \n",
      "Processing sample 2000 to 2100 \n",
      "Processing sample 2100 to 2200 \n",
      "Processing sample 2200 to 2300 \n",
      "Processing sample 2300 to 2400 \n",
      "Processing sample 2400 to 2500 \n",
      "Processing sample 2500 to 2600 \n",
      "Processing sample 2600 to 2700 \n",
      "Processing sample 2700 to 2800 \n",
      "Processing sample 2800 to 2900 \n",
      "Processing sample 2900 to 3000 \n",
      "Processing sample 3000 to 3100 \n",
      "Processing sample 3100 to 3200 \n",
      "Processing sample 3200 to 3300 \n",
      "Processing sample 3300 to 3400 \n",
      "Processing sample 3400 to 3500 \n",
      "Processing sample 3500 to 3600 \n",
      "Processing sample 3600 to 3700 \n",
      "Processing sample 3700 to 3800 \n",
      "Processing sample 3800 to 3900 \n",
      "Processing sample 3900 to 4000 \n",
      "Processing sample 4000 to 4100 \n",
      "Processing sample 4100 to 4200 \n",
      "Processing sample 4200 to 4300 \n",
      "Processing sample 4300 to 4400 \n",
      "Processing sample 4400 to 4500 \n",
      "Processing sample 4500 to 4600 \n",
      "Processing sample 4600 to 4700 \n",
      "Processing sample 4700 to 4800 \n",
      "Processing sample 4800 to 4900 \n",
      "Processing sample 4900 to 5000 \n",
      "Processing sample 5000 to 5100 \n",
      "Processing sample 5100 to 5200 \n",
      "Processing sample 5200 to 5300 \n",
      "Processing sample 5300 to 5400 \n",
      "Processing sample 5400 to 5500 \n",
      "Processing sample 5500 to 5600 \n",
      "Processing sample 5600 to 5700 \n",
      "Processing sample 5700 to 5800 \n",
      "Processing sample 5800 to 5900 \n",
      "Processing sample 5900 to 6000 \n",
      "Processing sample 6000 to 6100 \n",
      "Processing sample 6100 to 6200 \n",
      "Processing sample 6200 to 6300 \n",
      "Processing sample 6300 to 6400 \n",
      "Processing sample 6400 to 6500 \n",
      "Processing sample 6500 to 6600 \n",
      "Processing sample 6600 to 6700 \n",
      "Processing sample 6700 to 6800 \n",
      "Processing sample 6800 to 6900 \n",
      "Processing sample 6900 to 7000 \n",
      "Processing sample 7000 to 7100 \n",
      "Processing sample 7100 to 7200 \n",
      "Processing sample 7200 to 7300 \n",
      "Processing sample 7300 to 7400 \n",
      "Processing sample 7400 to 7500 \n",
      "Processing sample 7500 to 7600 \n",
      "Processing sample 7600 to 7700 \n",
      "Processing sample 7700 to 7800 \n",
      "Processing sample 7800 to 7900 \n",
      "Processing sample 7900 to 8000 \n",
      "Processing sample 8000 to 8100 \n",
      "Processing sample 8100 to 8200 \n",
      "Processing sample 8200 to 8300 \n",
      "Processing sample 8300 to 8400 \n",
      "Processing sample 8400 to 8500 \n",
      "Processing sample 8500 to 8600 \n",
      "Processing sample 8600 to 8700 \n",
      "Processing sample 8700 to 8800 \n",
      "Processing sample 8800 to 8900 \n",
      "Processing sample 8900 to 9000 \n",
      "Processing sample 9000 to 9100 \n",
      "Processing sample 9100 to 9200 \n",
      "Processing sample 9200 to 9300 \n",
      "Processing sample 9300 to 9400 \n",
      "Processing sample 9400 to 9500 \n",
      "Processing sample 9500 to 9600 \n",
      "Processing sample 9600 to 9700 \n",
      "Processing sample 9700 to 9800 \n",
      "Processing sample 9800 to 9900 \n",
      "Processing sample 9900 to 10000 \n",
      "Processing sample 10000 to 10100 \n",
      "Processing sample 10100 to 10200 \n",
      "Processing sample 10200 to 10300 \n",
      "Processing sample 10300 to 10400 \n",
      "Processing sample 10400 to 10500 \n",
      "Processing sample 10500 to 10600 \n",
      "Processing sample 10600 to 10700 \n",
      "Processing sample 10700 to 10800 \n",
      "Processing sample 10800 to 10900 \n",
      "Processing sample 10900 to 11000 \n",
      "Processing sample 11000 to 11100 \n",
      "Processing sample 11100 to 11200 \n",
      "Processing sample 11200 to 11300 \n",
      "Processing sample 11300 to 11400 \n",
      "Processing sample 11400 to 11500 \n",
      "Processing sample 11500 to 11600 \n",
      "Processing sample 11600 to 11700 \n",
      "Processing sample 11700 to 11800 \n",
      "Processing sample 11800 to 11900 \n",
      "Processing sample 11900 to 12000 \n",
      "Processing sample 12000 to 12100 \n",
      "Processing sample 12100 to 12200 \n",
      "Processing sample 12200 to 12300 \n",
      "Processing sample 12300 to 12400 \n",
      "Processing sample 12400 to 12500 \n",
      "Processing sample 12500 to 12600 \n",
      "Processing sample 12600 to 12700 \n",
      "Processing sample 12700 to 12800 \n",
      "Processing sample 12800 to 12900 \n",
      "Processing sample 12900 to 13000 \n",
      "Processing sample 13000 to 13100 \n",
      "Processing sample 13100 to 13200 \n",
      "Processing sample 13200 to 13300 \n",
      "Processing sample 13300 to 13400 \n",
      "Processing sample 13400 to 13500 \n",
      "Processing sample 13500 to 13600 \n",
      "Processing sample 13600 to 13700 \n",
      "Processing sample 13700 to 13800 \n",
      "Processing sample 13800 to 13900 \n",
      "Processing sample 13900 to 14000 \n",
      "Processing sample 14000 to 14100 \n",
      "Processing sample 14100 to 14200 \n",
      "Processing sample 14200 to 14300 \n",
      "Processing sample 14300 to 14400 \n",
      "Processing sample 14400 to 14500 \n",
      "Processing sample 14500 to 14600 \n",
      "Processing sample 14600 to 14700 \n",
      "Processing sample 14700 to 14800 \n",
      "Processing sample 14800 to 14900 \n",
      "Processing sample 14900 to 15000 \n",
      "Processing sample 15000 to 15100 \n",
      "Processing sample 15100 to 15200 \n",
      "Processing sample 15200 to 15300 \n",
      "Processing sample 15300 to 15400 \n",
      "Processing sample 15400 to 15500 \n",
      "Processing sample 15500 to 15600 \n",
      "Processing sample 15600 to 15700 \n",
      "Processing sample 15700 to 15800 \n",
      "Processing sample 15800 to 15900 \n",
      "Processing sample 15900 to 16000 \n",
      "Processing sample 16000 to 16100 \n",
      "Processing sample 16100 to 16200 \n",
      "Processing sample 16200 to 16300 \n",
      "Processing sample 16300 to 16400 \n",
      "Processing sample 16400 to 16500 \n",
      "Processing sample 16500 to 16600 \n",
      "Processing sample 16600 to 16700 \n",
      "Processing sample 16700 to 16800 \n",
      "Processing sample 16800 to 16900 \n",
      "Processing sample 16900 to 17000 \n",
      "Processing sample 17000 to 17100 \n",
      "Processing sample 17100 to 17200 \n",
      "Processing sample 17200 to 17300 \n",
      "Processing sample 17300 to 17400 \n",
      "Processing sample 17400 to 17500 \n",
      "Processing sample 17500 to 17600 \n",
      "Processing sample 17600 to 17700 \n",
      "Processing sample 17700 to 17800 \n",
      "Processing sample 17800 to 17900 \n",
      "Processing sample 17900 to 18000 \n",
      "Processing sample 18000 to 18100 \n",
      "Processing sample 18100 to 18200 \n",
      "Processing sample 18200 to 18300 \n",
      "Processing sample 18300 to 18400 \n",
      "Processing sample 18400 to 18500 \n",
      "Processing sample 18500 to 18600 \n",
      "Processing sample 18600 to 18700 \n",
      "Processing sample 18700 to 18800 \n",
      "Processing sample 18800 to 18900 \n",
      "Processing sample 18900 to 19000 \n",
      "Processing sample 19000 to 19100 \n",
      "Processing sample 19100 to 19200 \n",
      "Processing sample 19200 to 19300 \n",
      "Processing sample 19300 to 19400 \n",
      "Processing sample 19400 to 19500 \n",
      "Processing sample 19500 to 19600 \n",
      "Processing sample 19600 to 19700 \n",
      "Processing sample 19700 to 19800 \n",
      "Processing sample 19800 to 19900 \n",
      "Processing sample 19900 to 20000 \n",
      "Processing sample 20000 to 20100 \n",
      "Processing sample 20100 to 20200 \n",
      "Processing sample 20200 to 20300 \n",
      "Processing sample 20300 to 20400 \n",
      "Processing sample 20400 to 20500 \n",
      "Processing sample 20500 to 20600 \n",
      "Processing sample 20600 to 20700 \n",
      "Processing sample 20700 to 20800 \n",
      "Processing sample 20800 to 20900 \n",
      "Processing sample 20900 to 21000 \n",
      "Processing sample 21000 to 21100 \n",
      "Processing sample 21100 to 21200 \n",
      "Processing sample 21200 to 21300 \n",
      "Processing sample 21300 to 21400 \n",
      "Processing sample 21400 to 21500 \n",
      "Processing sample 21500 to 21600 \n",
      "Processing sample 21600 to 21700 \n",
      "Processing sample 21700 to 21800 \n",
      "Processing sample 21800 to 21900 \n",
      "Processing sample 21900 to 22000 \n",
      "Processing sample 22000 to 22100 \n",
      "Processing sample 22100 to 22200 \n",
      "Processing sample 22200 to 22300 \n",
      "Processing sample 22300 to 22400 \n",
      "Processing sample 22400 to 22500 \n",
      "Processing sample 22500 to 22600 \n",
      "Processing sample 22600 to 22700 \n",
      "Processing sample 22700 to 22800 \n",
      "Processing sample 22800 to 22900 \n",
      "Processing sample 22900 to 23000 \n",
      "Processing sample 23000 to 23100 \n",
      "Processing sample 23100 to 23200 \n",
      "Processing sample 23200 to 23300 \n",
      "Processing sample 23300 to 23400 \n",
      "Processing sample 23400 to 23500 \n",
      "Processing sample 23500 to 23600 \n",
      "Processing sample 23600 to 23700 \n",
      "Processing sample 23700 to 23800 \n",
      "Processing sample 23800 to 23900 \n",
      "Processing sample 23900 to 24000 \n",
      "Processing sample 24000 to 24100 \n",
      "Processing sample 24100 to 24200 \n",
      "Processing sample 24200 to 24300 \n",
      "Processing sample 24300 to 24400 \n",
      "Processing sample 24400 to 24500 \n",
      "Processing sample 24500 to 24600 \n",
      "Processing sample 24600 to 24700 \n",
      "Processing sample 24700 to 24800 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sample 24800 to 24900 \n",
      "Processing sample 24900 to 25000 \n",
      "Processing sample 25000 to 25100 \n",
      "Processing sample 25100 to 25200 \n",
      "Processing sample 25200 to 25300 \n",
      "Processing sample 25300 to 25400 \n",
      "Processing sample 25400 to 25500 \n",
      "Processing sample 25500 to 25600 \n",
      "Processing sample 25600 to 25700 \n",
      "Processing sample 25700 to 25800 \n",
      "Processing sample 25800 to 25900 \n",
      "Processing sample 25900 to 26000 \n",
      "Processing sample 26000 to 26100 \n",
      "Processing sample 26100 to 26200 \n",
      "Processing sample 26200 to 26300 \n",
      "Processing sample 26300 to 26400 \n",
      "Processing sample 26400 to 26500 \n",
      "Processing sample 26500 to 26600 \n",
      "Processing sample 26600 to 26700 \n",
      "Processing sample 26700 to 26800 \n",
      "Processing sample 26800 to 26900 \n",
      "Processing sample 26900 to 27000 \n",
      "Processing sample 27000 to 27100 \n",
      "Processing sample 27100 to 27200 \n",
      "Processing sample 27200 to 27300 \n",
      "Processing sample 27300 to 27400 \n",
      "Processing sample 27400 to 27500 \n",
      "Processing sample 27500 to 27600 \n",
      "Processing sample 27600 to 27700 \n",
      "Processing sample 27700 to 27800 \n",
      "Processing sample 27800 to 27900 \n",
      "Processing sample 27900 to 28000 \n",
      "Processing sample 28000 to 28100 \n",
      "Processing sample 28100 to 28200 \n",
      "Processing sample 28200 to 28300 \n",
      "Processing sample 28300 to 28400 \n",
      "Processing sample 28400 to 28500 \n",
      "Processing sample 28500 to 28600 \n",
      "Processing sample 28600 to 28700 \n",
      "Processing sample 28700 to 28800 \n",
      "Processing sample 28800 to 28900 \n",
      "Processing sample 28900 to 29000 \n",
      "Processing sample 29000 to 29100 \n",
      "Processing sample 29100 to 29200 \n",
      "Processing sample 29200 to 29300 \n",
      "Processing sample 29300 to 29400 \n",
      "Processing sample 29400 to 29500 \n",
      "Processing sample 29500 to 29600 \n",
      "Processing sample 29600 to 29700 \n",
      "Processing sample 29700 to 29800 \n",
      "Processing sample 29800 to 29900 \n",
      "Processing sample 29900 to 30000 \n",
      "Processing sample 30000 to 30100 \n",
      "Processing sample 30100 to 30200 \n",
      "Processing sample 30200 to 30300 \n",
      "Processing sample 30300 to 30400 \n",
      "Processing sample 30400 to 30500 \n",
      "Processing sample 30500 to 30600 \n",
      "Processing sample 30600 to 30700 \n",
      "Processing sample 30700 to 30800 \n",
      "Processing sample 30800 to 30900 \n",
      "Processing sample 30900 to 31000 \n",
      "Processing sample 31000 to 31100 \n",
      "Processing sample 31100 to 31200 \n",
      "Processing sample 31200 to 31300 \n",
      "Processing sample 31300 to 31400 \n",
      "Processing sample 31400 to 31500 \n",
      "Processing sample 31500 to 31600 \n",
      "Processing sample 31600 to 31700 \n",
      "Processing sample 31700 to 31800 \n",
      "Processing sample 31800 to 31900 \n",
      "Processing sample 31900 to 32000 \n",
      "Processing sample 32000 to 32100 \n",
      "Processing sample 32100 to 32200 \n",
      "Processing sample 32200 to 32300 \n",
      "Processing sample 32300 to 32400 \n",
      "Processing sample 32400 to 32500 \n",
      "Processing sample 32500 to 32600 \n",
      "Processing sample 32600 to 32700 \n",
      "Processing sample 32700 to 32800 \n",
      "Processing sample 32800 to 32900 \n",
      "Processing sample 32900 to 33000 \n",
      "Processing sample 33000 to 33100 \n",
      "Processing sample 33100 to 33200 \n",
      "Processing sample 33200 to 33300 \n",
      "Processing sample 33300 to 33400 \n",
      "Processing sample 33400 to 33500 \n",
      "Processing sample 33500 to 33600 \n",
      "Processing sample 33600 to 33700 \n",
      "Processing sample 33700 to 33800 \n",
      "Processing sample 33800 to 33900 \n",
      "Processing sample 33900 to 34000 \n",
      "Processing sample 34000 to 34100 \n",
      "Processing sample 34100 to 34200 \n",
      "Processing sample 34200 to 34300 \n",
      "Processing sample 34300 to 34400 \n",
      "Processing sample 34400 to 34500 \n",
      "Processing sample 34500 to 34600 \n",
      "Processing sample 34600 to 34700 \n",
      "Processing sample 34700 to 34800 \n",
      "Processing sample 34800 to 34900 \n",
      "Processing sample 34900 to 35000 \n",
      "Processing sample 35000 to 35100 \n",
      "Processing sample 35100 to 35200 \n",
      "Processing sample 35200 to 35300 \n",
      "Processing sample 35300 to 35400 \n",
      "Processing sample 35400 to 35500 \n",
      "Processing sample 35500 to 35600 \n",
      "Processing sample 35600 to 35700 \n",
      "Processing sample 35700 to 35800 \n",
      "Processing sample 35800 to 35900 \n",
      "Processing sample 35900 to 36000 \n",
      "Processing sample 36000 to 36100 \n",
      "Processing sample 36100 to 36200 \n",
      "Processing sample 36200 to 36300 \n",
      "Processing sample 36300 to 36400 \n",
      "Processing sample 36400 to 36500 \n",
      "Processing sample 36500 to 36600 \n",
      "Processing sample 36600 to 36700 \n",
      "Processing sample 36700 to 36800 \n",
      "Processing sample 36800 to 36900 \n",
      "Processing sample 36900 to 37000 \n",
      "Processing sample 37000 to 37100 \n",
      "Processing sample 37100 to 37200 \n",
      "Processing sample 37200 to 37300 \n",
      "Processing sample 37300 to 37400 \n",
      "Processing sample 37400 to 37500 \n",
      "Processing sample 37500 to 37600 \n",
      "Processing sample 37600 to 37700 \n",
      "Processing sample 37700 to 37800 \n",
      "Processing sample 37800 to 37900 \n",
      "Processing sample 37900 to 38000 \n",
      "Processing sample 38000 to 38100 \n",
      "Processing sample 38100 to 38200 \n",
      "Processing sample 38200 to 38300 \n",
      "Processing sample 38300 to 38400 \n",
      "Processing sample 38400 to 38500 \n",
      "Processing sample 38500 to 38600 \n",
      "Processing sample 38600 to 38700 \n",
      "Processing sample 38700 to 38800 \n",
      "Processing sample 38800 to 38900 \n",
      "Processing sample 38900 to 39000 \n",
      "Processing sample 39000 to 39100 \n",
      "Processing sample 39100 to 39200 \n",
      "Processing sample 39200 to 39300 \n",
      "Processing sample 39300 to 39400 \n",
      "Processing sample 39400 to 39500 \n",
      "Processing sample 39500 to 39600 \n",
      "Processing sample 39600 to 39700 \n",
      "Processing sample 39700 to 39800 \n",
      "Processing sample 39800 to 39900 \n",
      "Processing sample 39900 to 40000 \n",
      "Processing sample 0 to 100 \n",
      "Processing sample 100 to 200 \n",
      "Processing sample 200 to 300 \n",
      "Processing sample 300 to 400 \n",
      "Processing sample 400 to 500 \n",
      "Processing sample 500 to 600 \n",
      "Processing sample 600 to 700 \n",
      "Processing sample 700 to 800 \n",
      "Processing sample 800 to 900 \n",
      "Processing sample 900 to 1000 \n",
      "Processing sample 1000 to 1100 \n",
      "Processing sample 1100 to 1200 \n",
      "Processing sample 1200 to 1300 \n",
      "Processing sample 1300 to 1400 \n",
      "Processing sample 1400 to 1500 \n",
      "Processing sample 1500 to 1600 \n",
      "Processing sample 1600 to 1700 \n",
      "Processing sample 1700 to 1800 \n",
      "Processing sample 1800 to 1900 \n",
      "Processing sample 1900 to 2000 \n",
      "Processing sample 2000 to 2100 \n",
      "Processing sample 2100 to 2200 \n",
      "Processing sample 2200 to 2300 \n",
      "Processing sample 2300 to 2400 \n",
      "Processing sample 2400 to 2500 \n",
      "Processing sample 2500 to 2600 \n",
      "Processing sample 2600 to 2700 \n",
      "Processing sample 2700 to 2800 \n",
      "Processing sample 2800 to 2900 \n",
      "Processing sample 2900 to 3000 \n",
      "Processing sample 3000 to 3100 \n",
      "Processing sample 3100 to 3200 \n",
      "Processing sample 3200 to 3300 \n",
      "Processing sample 3300 to 3400 \n",
      "Processing sample 3400 to 3500 \n",
      "Processing sample 3500 to 3600 \n",
      "Processing sample 3600 to 3700 \n",
      "Processing sample 3700 to 3800 \n",
      "Processing sample 3800 to 3900 \n",
      "Processing sample 3900 to 4000 \n",
      "Processing sample 4000 to 4100 \n",
      "Processing sample 4100 to 4200 \n",
      "Processing sample 4200 to 4300 \n",
      "Processing sample 4300 to 4400 \n",
      "Processing sample 4400 to 4500 \n",
      "Processing sample 4500 to 4600 \n",
      "Processing sample 4600 to 4700 \n",
      "Processing sample 4700 to 4800 \n",
      "Processing sample 4800 to 4900 \n",
      "Processing sample 4900 to 5000 \n",
      "Processing sample 5000 to 5100 \n",
      "Processing sample 5100 to 5200 \n",
      "Processing sample 5200 to 5300 \n",
      "Processing sample 5300 to 5400 \n",
      "Processing sample 5400 to 5500 \n",
      "Processing sample 5500 to 5600 \n",
      "Processing sample 5600 to 5700 \n",
      "Processing sample 5700 to 5800 \n",
      "Processing sample 5800 to 5900 \n",
      "Processing sample 5900 to 6000 \n",
      "Processing sample 6000 to 6100 \n",
      "Processing sample 6100 to 6200 \n",
      "Processing sample 6200 to 6300 \n",
      "Processing sample 6300 to 6400 \n",
      "Processing sample 6400 to 6500 \n",
      "Processing sample 6500 to 6600 \n",
      "Processing sample 6600 to 6700 \n",
      "Processing sample 6700 to 6800 \n",
      "Processing sample 6800 to 6900 \n",
      "Processing sample 6900 to 7000 \n",
      "Processing sample 7000 to 7100 \n",
      "Processing sample 7100 to 7200 \n",
      "Processing sample 7200 to 7300 \n",
      "Processing sample 7300 to 7400 \n",
      "Processing sample 7400 to 7500 \n",
      "Processing sample 7500 to 7600 \n",
      "Processing sample 7600 to 7700 \n",
      "Processing sample 7700 to 7800 \n",
      "Processing sample 7800 to 7900 \n",
      "Processing sample 7900 to 8000 \n",
      "Processing sample 8000 to 8100 \n",
      "Processing sample 8100 to 8200 \n",
      "Processing sample 8200 to 8300 \n",
      "Processing sample 8300 to 8400 \n",
      "Processing sample 8400 to 8500 \n",
      "Processing sample 8500 to 8600 \n",
      "Processing sample 8600 to 8700 \n",
      "Processing sample 8700 to 8800 \n",
      "Processing sample 8800 to 8900 \n",
      "Processing sample 8900 to 9000 \n",
      "Processing sample 9000 to 9100 \n",
      "Processing sample 9100 to 9200 \n",
      "Processing sample 9200 to 9300 \n",
      "Processing sample 9300 to 9400 \n",
      "Processing sample 9400 to 9500 \n",
      "Processing sample 9500 to 9600 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sample 9600 to 9700 \n",
      "Processing sample 9700 to 9800 \n",
      "Processing sample 9800 to 9900 \n",
      "Processing sample 9900 to 10000 \n"
     ]
    }
   ],
   "source": [
    "# Generate Pre-trained outputs \n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = TFBertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "n_dim = 768 \n",
    "def compute_bert_pt(text_data, batch_size): \n",
    "  i = 0; \n",
    "  output = tf.reshape(tf.constant([]), (0, n_dim))\n",
    "  while i*batch_size < text_data.shape[0]:\n",
    "    start = i*batch_size \n",
    "    end = (i+1)*batch_size\n",
    "    if end > text_data.shape[0]: \n",
    "      end = text_data.shape[0] \n",
    "    batch_pt = bert_model(tokenizer(text_data[start:end].tolist(), max_length = 512, pad_to_max_length=True, truncation=True, return_tensors='tf'))['pooler_output'] \n",
    "    output = tf.concat([output, batch_pt], 0)\n",
    "    print(f'Processing sample {start} to {end} ')\n",
    "    i+=1\n",
    "  return output\n",
    "\n",
    "X_train_pt = compute_bert_pt(X_train, 100)\n",
    "X_test_pt = compute_bert_pt(X_test, 100) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 768)\n",
      "(40000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_pt.shape)\n",
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        [(None, 768)]             0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 128)               98432     \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 98,561\n",
      "Trainable params: 98,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(n_dim), dtype=tf.float32)\n",
    "outputs = tf.keras.layers.Dropout(0.1)(inputs)\n",
    "outputs = tf.keras.layers.Dense(128, activation='relu')(inputs)\n",
    "outputs = tf.keras.layers.Dropout(0.1)(outputs)\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(outputs)\n",
    "model =  tf.keras.Model(inputs, outputs)\n",
    "print(model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f626441d4c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1233/1250 [============================>.] - ETA: 0s - loss: 0.4899 - accuracy: 0.7615WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f62643171f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.4894 - accuracy: 0.7618 - val_loss: 0.4944 - val_accuracy: 0.7613\n",
      "Epoch 2/8\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.4070 - accuracy: 0.8158 - val_loss: 0.3718 - val_accuracy: 0.8360\n",
      "Epoch 3/8\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.3942 - accuracy: 0.8235 - val_loss: 0.3603 - val_accuracy: 0.8452\n",
      "Epoch 4/8\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.3859 - accuracy: 0.8281 - val_loss: 0.3660 - val_accuracy: 0.8423\n",
      "Epoch 5/8\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.3796 - accuracy: 0.8318 - val_loss: 0.3573 - val_accuracy: 0.8420\n",
      "Epoch 6/8\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.3777 - accuracy: 0.8324 - val_loss: 0.4277 - val_accuracy: 0.8075\n",
      "Epoch 7/8\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.3704 - accuracy: 0.8362 - val_loss: 0.3823 - val_accuracy: 0.8248\n",
      "Epoch 8/8\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.3682 - accuracy: 0.8375 - val_loss: 0.3492 - val_accuracy: 0.8505\n"
     ]
    }
   ],
   "source": [
    "model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "history =  model.fit(X_train_pt, y_train, batch_size=32, epochs=8, validation_data=(X_test_pt, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
